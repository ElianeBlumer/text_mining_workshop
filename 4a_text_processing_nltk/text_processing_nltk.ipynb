{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk\n",
    "nltk.download() # you need only to download example from the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "\n",
    "A typical NLP pipeline increasingly extracts metadata, in order to extract higher-level information, for example **biomedical 'events'**:\n",
    "\n",
    "1. Gene Expression between the trigger word “expression” and the protein “interferon regulatory factor 4″; and\n",
    "2. Negative Regulation between the trigger “Down-regulation” and “expression”, representing event 1.\n",
    "\n",
    "![event](biomedical_event.jpg)\n",
    "\n",
    "The figure below presents an NLP pipeline to recognize such 'events'. It contains the following steps:\n",
    "\n",
    "* Reader: read input data and mark the text regions of interest;\n",
    "* NLP-Preprocessing: perform sentence splitting and tokenization, lemmatization, part-of-speech (POS) tagging, chunking and dependency parsing;\n",
    "* Concept loader: load relevant concepts;\n",
    "* Dictionary tagger: perform trigger recognition using previously built dictionaries;\n",
    "* Machine learning: perform trigger recognition using previously trained models;\n",
    "* Post-processing: remove false positive trigger names through rule-based approaches;\n",
    "* Writer: write the output to an external resource.\n",
    "\n",
    "![nlp](nlp.png)\n",
    "\n",
    "(source: David Campos, http://doi.org/10.1186/1751-0473-9-1)\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Let's get started ourselves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization** (splitting sentences & words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'just', 'ate', 'the', 'cake', 'with', 'a', 'spoon']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I just ate the cake with a spoon\"\n",
    "words = nltk.word_tokenize( text )\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part of speech tagging** assigns the most probable POS to each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('ate', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('cake', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('spoon', 'NN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only words:  ['cake', 'spoon']\n",
      "only verbs:  ['ate']\n"
     ]
    }
   ],
   "source": [
    "print('only words: ', [w[0] for w in nltk.pos_tag(words) if w[1].startswith('N')])\n",
    "print('only verbs: ', [w[0] for w in nltk.pos_tag(words) if w[1].startswith('V')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chunking** and **named entity recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSON Barack/NNP)\n",
      "(ORGANIZATION Obama/NNP)\n",
      "('meets', 'VBZ')\n",
      "(PERSON Michael/NNP Jackson/NNP)\n",
      "('in', 'IN')\n",
      "(GPE Nihonbashi/NNP)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, ne_chunk, pos_tag\n",
    "text2 = \"Barack Obama meets Michael Jackson in Nihonbashi\"\n",
    "chunked = ne_chunk(pos_tag(word_tokenize(text2)))\n",
    "for i in chunked:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
