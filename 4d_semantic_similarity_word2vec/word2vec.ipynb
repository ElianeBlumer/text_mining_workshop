{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import word2vec # pip install word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is equivalent to `demo-word.sh`, `demo-analogy.sh`, `demo-phrases.sh` and `demo-classes.sh` from the original [Google code](https://code.google.com/p/word2vec/).\n",
    "\n",
    "Source: http://nbviewer.ipython.org/github/danielfrg/word2vec/blob/master/examples/word2vec.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2015-11-26 16:51:59--  http://mattmahoney.net/dc/text8.zip\n",
      "Resolving mattmahoney.net... 98.139.135.129\n",
      "Connecting to mattmahoney.net|98.139.135.129|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31344016 (30M) [application/zip]\n",
      "Saving to: 'text8.zip'\n",
      "\n",
      "text8.zip           100%[=====================>]  29.89M  1.33MB/s   in 23s    \n",
      "\n",
      "2015-11-26 16:52:22 (1.30 MB/s) - 'text8.zip' saved [31344016/31344016]\n",
      "\n",
      "Archive:  text8.zip\n",
      "  inflating: text8                   \n",
      "Starting training using file text8\n",
      "Words processed: 17000K     Vocab size: 4399K  \n",
      "Vocab size (unigrams + bigrams): 2419827\n",
      "Words in train file: 17005206\n",
      "Starting training using file text8-phrases\n",
      "Vocab size: 98331\n",
      "Words in train file: 15857306\n",
      "Alpha: 0.000002  Progress: 100.03%  Words/thread/sec: 245.75k  "
     ]
    }
   ],
   "source": [
    "# you can skip that part and use the pretrained model, see below\n",
    "\n",
    "# Download some data, for example: \n",
    "!wget http://mattmahoney.net/dc/text8.zip\n",
    "!unzip text8.zip\n",
    "\n",
    "# Run `word2phrase` to group up similar words \"Los Angeles\" to \"Los_Angeles\"\n",
    "word2vec.word2phrase('text8', 'text8-phrases', verbose=True)\n",
    "# This will create a text8-phrases that we can use as a better input for word2vec. \n",
    "# Note that you could easily skip this previous step and use the origial data as input for word2vec.\n",
    "\n",
    "# Train the model using the word2phrase output.\n",
    "word2vec.word2vec('text8-phrases', 'text8.bin', size=100, verbose=True)\n",
    "# That generated a `text8.bin` file containing the word vectors in a binary format.\n",
    "print('training complete :-)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model file created above, or download it from https://dl.dropboxusercontent.com/u/975350/tmp/text8.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = word2vec.load('text8.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the vocabulaty as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'</s>', u'the', u'of', ..., u'dakotas', u'nias', u'burlesques'], \n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or take a look at the whole matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98331, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14333282,  0.15825513, -0.13715845, ...,  0.05456942,\n",
       "         0.10955409,  0.00693387],\n",
       "       [ 0.14694442, -0.00921887,  0.04583032, ..., -0.03086229,\n",
       "        -0.05368164, -0.10046262],\n",
       "       [ 0.16525993,  0.04536457,  0.04944701, ...,  0.05263765,\n",
       "         0.1678641 ,  0.0518899 ],\n",
       "       ..., \n",
       "       [-0.06522302,  0.07457283,  0.03537172, ...,  0.15117142,\n",
       "        -0.04217494, -0.07174871],\n",
       "       [ 0.00877762,  0.0425899 ,  0.14123389, ..., -0.0597503 ,\n",
       "        -0.09166503, -0.0475128 ],\n",
       "       [-0.01401589, -0.07021915,  0.10536838, ...,  0.03014692,\n",
       "        -0.08648375, -0.09778806]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retreive the vector of individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['dog'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10332464,  0.06703388,  0.05134746,  0.08328107,  0.08478329,\n",
       "       -0.029021  ,  0.01412035,  0.13168371,  0.08635285, -0.05263404])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['dog'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do simple queries to retreive words similar to \"socks\" based on cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'blue', 0.9102310124344305),\n",
       " (u'yellow', 0.8952224651112171),\n",
       " (u'green', 0.8222502950427031),\n",
       " (u'purple', 0.8189022284021563),\n",
       " (u'orange', 0.8147085127359422),\n",
       " (u'white', 0.8103996728750976),\n",
       " (u'black', 0.7809016351589374),\n",
       " (u'pink', 0.7522223146405485),\n",
       " (u'grey', 0.7417127727132912),\n",
       " (u'colored', 0.7313320169929519)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine('red')\n",
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'tofu', 0.8876018411826816),\n",
       " (u'grilled', 0.8825909072946603),\n",
       " (u'noodles', 0.8727839960713353),\n",
       " (u'mustard', 0.8660121928025903),\n",
       " (u'salted', 0.8633289673644092),\n",
       " (u'broth', 0.8582858806598598),\n",
       " (u'liqueur', 0.8582677050451581),\n",
       " (u'soda', 0.8552275215675876),\n",
       " (u'eggplant', 0.855012967375358),\n",
       " (u'soy_sauce', 0.8549815457362573)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine('sausage')\n",
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we trained the model with the output of `word2phrase` we can ask for similarity of \"phrases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'san_francisco', 0.8907173960415067),\n",
       " (u'san_diego', 0.8764709136380514),\n",
       " (u'seattle', 0.8387995826597778),\n",
       " (u'las_vegas', 0.8315778508753239),\n",
       " (u'california', 0.8295829170840956),\n",
       " (u'chicago', 0.8292007306509285),\n",
       " (u'cleveland', 0.8267398709931983),\n",
       " (u'miami', 0.8244456208850379),\n",
       " (u'detroit', 0.8200824457281422),\n",
       " (u'chicago_illinois', 0.8173753945669766)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine('los_angeles')\n",
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its possible to do more complex queries like analogies such as: `king - man + woman = queen` \n",
    "This method returns the same as `cosine` the indexes of the words in the vocab and the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'queen', 0.2880241341290669),\n",
       " (u'prince', 0.27092894724490246),\n",
       " (u'son', 0.26934393426434866),\n",
       " (u'empress', 0.2684484402477858),\n",
       " (u'wife', 0.2646606373064051),\n",
       " (u'emperor', 0.2633477131940194),\n",
       " (u'regent', 0.25994703729205215),\n",
       " (u'throne', 0.25966095236175724),\n",
       " (u'aragon', 0.25878382226993896),\n",
       " (u'monarch', 0.25648878233523753)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.analogy(pos=['king', 'woman'], neg=['man'], n=10)\n",
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see get all the words grouped on an specific cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
